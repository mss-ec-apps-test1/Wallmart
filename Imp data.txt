400 Bad Request
The server could not understand the request due to invalid syntax.

401 Unauthorized
Although the HTTP standard specifies "unauthorized", semantically this response means "unauthenticated". That is, the client must authenticate itself to get the requested response.

402 Payment Required 
This response code is reserved for future use. The initial aim for creating this code was using it for digital payment systems, however this status code is used very rarely and no standard convention exists.

403 Forbidden
The client does not have access rights to the content; that is, it is unauthorized, so the server is refusing to give the requested resource. Unlike 401, the client's identity is known to the server.

404 Not Found
The server can not find the requested resource. In the browser, this means the URL is not recognized. In an API, this can also mean that the endpoint is valid but the resource itself does not exist. Servers may also send this response instead of 403 to hide the existence of a resource from an unauthorized client. This response code is probably the most famous one due to its frequent occurrence on the web.

405 Method Not Allowed
The request method is known by the server but is not supported by the target resource. For example, an API may forbid DELETE-ing a resource.

406 Not Acceptable
This response is sent when the web server, after performing server-driven content negotiation, doesn't find any content that conforms to the criteria given by the user agent.

407 Proxy Authentication Required
This is similar to 401 but authentication is needed to be done by a proxy.

408 Request Timeout
This response is sent on an idle connection by some servers, even without any previous request by the client. It means that the server would like to shut down this unused connection. This response is used much more since some browsers, like Chrome, Firefox 27+, or IE9, use HTTP pre-connection mechanisms to speed up surfing. Also note that some servers merely shut down the connection without sending this message.


AWS: 

Day1: -

CAPEX -> capital expenditure
OPEX -> operational Expenditure

Datacenter Infrastructure management
------------------------------------------------------
1.	Dedicated space
2.	High bandwidth
3.	Redundant power supply
4.	Support Availability
5.	Leadership Experience
6.	Time consuming
7.	Higher maintenance Effort
8.	Capacity Planning

Business requirement
-------------------------------
1.	High Availability
2.	Fault Tolerant
3.	Scalability
4.	Elasticity

Cloud Services
--------------------
Services on demand, pay as you go model

Cloud Computing
------------------------
Delivery of comuting services like servers, storage, databases etc

Advantage of cloud
---------------------------
1.	cost-Effectiveness - Pay as you Go
2.	scalability and elasticity
3.	Reliable and High Availability
4.	speed or Agility
5.	Deploy globally in minutes
6.	Security

Types of cloud
---------------------
1.	public cloud - AWS, GCP and Microsoft Azure
2.	private cloud - Openshift and IBM Cloud
3.	Hybrid cloud
4.	Multi cloud


Cloud Service Models
------------------------------
•	On Premises - Networking, Storage, servers, Virtualization , O/s, Middleware, Runtime, Data , Applications(By own)
•	IAAS - Networking, Storage, servers, Virtualization
•	PAAS - Networking, Storage, servers, Virtualization , O/s, Middleware, Runtime
•	SAAS - Networking, Storage, servers, Virtualization , O/s, Middleware, Runtime, Data , Applications
 
Popular Cloud providers
---------------------------------
•	AWS
•	Microsoft Azure
•	GCP
•	VMware
•	IBM Cloud
•	Oracle Cloud
•	Rackspace
•	Redhat
•	Salesforce

AWS Global Infrastructure
------------------------------------
Region - 25, planning 8 more
Availability Zones - 81, planning 24 more


Day2: -

How to choose the right region?
-------------------------------------------
•	pricing
•	End User/Customer Location
•	Latency (To check the latency https://www.cloudping.info/ or https://ping.psa.fun/ )
•	Security and Compliance Requirement
•	Service Availability

EC2 Instance components
-----------------------------------
•	AMI's
•	Instance type
•	EBS(local storage)
•	IP Addressing
•	Security Groups
•	KEY pair

EC2 Purchasing Option
----------------------------------

On Demand: -
------------------
•	Most expensive purchasing option
•	Most flexible purchasing option
•	You are charged only when instance is Running(billed by hour)
•	You can provision/terminate an instance anytime

Reserved: -
-----------------
•	Allows us to purchase an instance for a set time period (1/3 yrs
•	Significant price discount
•	Once you buy a reserved instance, we are responsible for the entire price
•	Regardless of how often we use it

Spot: -
-----------
•	Amazon sells the unused instances, for short amount of time at lower price
•	We can Bid on an instance type & only use when the spot price is equal to or below your bid price
•	Charged by hour
•	Spot price fluctuate based on supply & demand in market




Dedicated Instance
--------------------------
•	Instances running on hardware that’s dedicated to you. If you stop/start instance, you can get some other hardware somewhere else.

Dedicated host
---------------------
•	Physical dedicated server for your use. It’s always the same physical machine for as long as you are paying.

Instance Family & Type
---------------------------------
1.	General purpose – balanced memory and CPU (t2, m3, m4)
2.	Compute optimized – More CPU then RAM (c3, c4, cc2) – C types
3.	Memory optimized – More RAM – M type and R type
4.	Storage optimized – Low latency (d2, i2, i3) – D and I type
5.	Accelerated computing (GPU) – Graphics optimized
6.	High memory Optimized – High RAM, Nitro system
7.	Previous generation
8.	EBS Optimized (Option for higher IOPS performance)

Instance Type Components
---------------------------------------
•	Family: Categorizing instance types based on what they are optimized for
•	Type: subcategory for each family type
•	vCPUs: number of virtual CPUs the instance type uses
•	Memory: Amount of RAM the instance type uses
•	Instance Storage(GB): local instance storage volume(hard drive)
•	EBS Optimized Available: Indicates if EBS optimization is an option for the instance type
•	Network Performance: Rating based on its data transfer rate(bandwidth)

Thing you do to select an AMI
-------------------------------------------
AMIs come in 2 main categories: -
1) Community AMIs:
- Free to use
- Generally it contains only the OS

2) AWS Marketplace AMIs:
- pay to use
- Generally comes packaged with additional licensed software

3) My AMIs:
- AMIs that you can create yourself



Security Groups
-------------------------
1. Act as a firewall for any EC2 Instance
2. Control the traffic by Inbound and Outbound rules
3. Security Group is stateless means you have to configure inbound and outbound separately for any traffic.

Day3: -

IP Address
-----------
1. Public IP - Accessible from Internet and will change after restart.
2. Private IP - Not able to access through Internet. It should be from any class, A, B, C 
3. Elastic IP - Fixed Public ip and will be chargable.

Storage
--------
1. Local storage - temperory - Instance store
2. EBS Storage
3. EFS storage
4. S3

Storage types
---------------
1. Block storage - Data store in multiple Block and each block have their inode value - Ex EBS - SSD(GP2/GP3/IO2/IO3) or Magnetic type - root volume - Good performnace for I/O
2. File storage - Data store in a file - Ex EFS
3. Object storage - Data store as an object. Each object have their end point - Ex S3

Note:-
------
1. We can access or read/write on EBS and EFS after mounting it.
2. EBS volume and EC2 will be in same AZ if you want to mount EBS to EC2.
3. The min size value of EBS volume is 1 GB and Max 16384 GB.

Lab: -
-------
Create an EC2 Instance and create Volume in same AZ and attach the volume to EC2.Create filesystem on the mounted Volume by mkfs.ext4 /dev/xvdf and then mount any directory to the mounted volume by mount /dev/xvdf /var/lib/jenkins.

Note:-  
--------
1. We can not mount one volume simultaneously to multiple EC2.
2. You can increase the size of the created volume on fly but not able to decrease.

EBS Snapshot
-------------
Snapshot is nothing backup of your EBS Volumes.

snapshots can be taken two types: -

1. Manually using AWS GUI, CLI, APIS etc
   check mark on the volume -> Actions -> Take a snapshot (no need to stop the server)
2. By creating Lifecycle manager (For periodically based on policy)
   Life cycle manager -> Specify settings -> On the basis of tags on that volume
   Target resource type -> volume
   Target resource tags -> Name and value
   Schedule details

Restoring: -
-------------
In same region -> Actions -> create volume
In different region - > use Actions -> copy -> Choose Region and then convert the Snapshot to volume in that region.

Lab1:- Take a snapshot of the Jenkins Volume and copy that snapshot to Singapore Region. create an Instance in Singapore Region and install Jenkins, and mount the snapshot after converting to volume to Jenkins EC2

Lab2: - Recovery of Key file

Day5: -
------- 

Where do EBS snapshots will be stored/maintained by AWS?

EBS snapshots will be maintained in S3 buckets by AWS. But not available in our account.

Shared storage (EFS)
-------------------------------
We can mount this storage simultaneously.

EFS - Managed NFS -> you no need to configure NFS, managed by AWS. There is no fixed capacity, it can grow and shrink automatically.

Lab: - Create two EC2 in different AZ. Create EFS storage and share between two.

It can be shared to different AZ, Region or different Account.

Search EFS -> Create file system -> Name, VPC, Availability and Durability (Regional, One zone) - create

It need NFS client or EBS client installed on the system to mount.

Install NFS client on both system
# yum installl nfs-utils -y

Open the security group port 2049 of shared volume. You can get the SG id from netwrk section of EFS volume.

Mount the volume by below command
							  
Amazon FSX client - For windows 
FSx - For windows

S3: -
--------
Object Storage
Without mounting we can read and write on Object Storage from anywhere.

S3 is perfect place to maintain application static files like images, docs, audios, video file
S3 is perfect place to maintain application logs and backups.

Netflix Video streaming OTT platform hosted in AWS. 

S3 can be access either GUI, CLI, API, SDKS
When we upload any object into S3 we will get an endpoint for each and every object uploaded S3.
Each object will have unique id and endpoints (https URL)

S3 Buckets
Names should be unique across AWS globally.
How many S3 buckets we can create in one AWS account by default?
100 (Soft limit) - can be extended this limit by working with AWS team.

What is the max file capacity or file size limit in S3?
5TB/5000GB - Maximum size

Lab: - Create a bucket
Search S3 - create bucket -> Bucket Name, AWS Region, by default blocked public access. Versioning - default Disable- Enable this, Add Tag ->Default Encryption-Disabled - create bucket-> Upload some files.

Within this bucket we can upload and download files. Each and every file have endpoint which you can use in any application.

MAX file size 160GB we can upload through GUI.

We can manage a permission of any object
-Public access – access throughout internet
-Bucket policy – Granular level policy (from any source only) –in form of json
 
-ACL - Access control list (You can access within multiple account)
 

Can we do S3 replication without versioning enabled? – No
What is ARN in AWS?
Amazon Resource Name -Its unique way of identified each resource (service) in AWS

Day6: -

Storage Classes
----------------------
By default each object which is upload to S3 maintained in standard Storage class.
S3 charges is based on the object size and storage class.

1. Standard class -> The files which we are going to access frequently.
2. IA (Infrequent Access) -> The data is not going to access frequently for cost saving and less performance.
3. RRS/One zone (Reduced Redundancy Storage) -> Non critical $ Reproducible data. We can store in RSS. Chances to loss of data.
4. Glacier-> Archival data we can store in glacier with very less price. When we retrieve the data from Glacier it will be chargeable high. It take up to 4 hrs to read the data from Glacier. It is like a historical data.

Object Transition & Expiration can be automate using Object Life Cycle Rules.
--------------------------------------------------------------------------------------------------------
Object Lifecycle -> we can transit & move objects from one SC to another SC and also we can set expiration (delete) for the object using Object Life Cycle Rules.

Management -> Lifecycle Rules -> create Lifecycle rules
1. Name
2. Choose a rule scope
3. prefix
4. tags
5. Lifecycle rule actions

We can move from one class to another from any specific days or we can delete after some specific days.

To save the cost we implement Life cycle management.

Replication in S3 (Duplicate Copy)
----------------------------------------------
management -> replication rules -> create replication rules -> Name, status, source Bucket and scope, Destination and Bucket Name , IAM Role , storage class of replication

Replication should be done in same region as well as in different region.
Same account same region
Different Region Same account
Same Region Different Account
Different Different Account

Max file size which we can upload in S3?
5 TB

How many buckets we can create in one account by default?
100 (Soft limit)

Snow Ball (Device)
--------------------------
Data transfer of huge data from in-premises to AWS.

Write a request to AWS or job, they will send device to your data center, you connect that device and copy all data and then the device will be move to AWS data center and then they connect and copy your data.

VPC
-------
VPC: - Virtual Private Cloud (Private network)
Network -> Groups of devices which connected with each other some or the other way using network cables, routers, switches... etc.

LAN -> Local Area Network (Intranet)
WAN -> Wide Area Network (Internet)

When we create an AWS account by default there will be default vpc will be created for us.

Private Subnet
Public Subnet

VPC Tool Box
-------------------
1. VPC (max 5 VPC in one Account)
2. Subnets (max 200 subnets in One VPC)
3. NACL (Network Access Control List)
4. Routing Table
5. Internet Gateway
6. NAT

ELB -> Loadbalancer as a Service
--------------------------------------------

RDS -> Relational Data Base as a Service
------------------------------------------------------
Managed Databases (mysql, Postgres, mariadb etc.)

VPC Types: -

1)	Default VPC
2)	Custom VPC

Default VPC: -
•	Created in each AWS Region when an AWS account is created.
•	Has default CIDR, Security Group, NACL and Route table settings.
•	Has an Internet Gateway by default.

Custom VPC: -
•	Is a VPC on AWS Account owner creates.
•	AWS user creating the custom VPC can decide the CIDR
•	Has its own default security group, Network ACL and Route Tables.
•	Does not have an Internet Gateway by default, one needs to be created if needed.

Steps to create a VPC: -
1)	VPC
2)	Subnet
3)	Internet Gateway
4)	Route Table configuration

Public Subnet: - If a subnet traffic is routed to an Internet Gateway, the subnet is known as a public Subnet. If you want your instance in a public subnet to communicate with the internet over IPV4, it must have a public IPV4 address or an Elastic IP Address.

Private Subnet: - If a subnet does not have a route to the internet Gateway, the subnet is known as a Private Subnet. When you create a VPC, you must specify an IPV4 CIDR Block for the VPC. The allowed block size is between /16 to /28 netmask. The first four and last IP address of Subnet cannot assigned.

For ex: - for Network 10.0.0.0/16

10.0.0.0		Network Address     
10.0.0.1		Reserved by AWS for the VPC Router
10.0.0.2		Reserved by AWS for IP address of DNS server
10.0.0.3		Reserved for Future Use
10.0.0.255		Broadcast Address

Note: - AWS do not support Broadcast in a VPC but reserve this Address.

Implied or logical Router and Router table: -

	It is the central Routing function
	It connects the different AZ together and connects the VPC to the Internet gateway.
	You can have upto 200 Route tables per VPC.
	You can have upto 50 Routes entries per route table.
	Each subnet must be associated with only one route table at any given time.
	If you do not specify a subnet to route table association, the subnet will be associates with the VPC route table.
	You can also edit the main route table if you need, but you cannot delete main route table.
	However you can make a custom route table manually become the main Route table then you can delete the former main as it is no longer a main route table
	You can associate multiple subnets with the same Route table.

Internet Gateway: -

	The Internet Gateway is a virtual router that connects a VPC to the internet.
	Default VPC is already attached with an Internet gateway.
	If you create a new VPC then you must attach the Internet Gateway in order to access the Internet.
	Ensure that your public subnet route table points to the internet gateway.
	It performs NAT between your private and public IPV4 address.
	It supports both IPV4 and IPV6.

A Virtual Private Cloud is a Virtual Network that closely resembles a traditional Networking that you operate in your own data center, with the benefits of using the scalable infrastructure of AWS.

OR

VPC is a virtual network or datacenter inside AWS for one client.

•	It is logically isolated from other virtual N/W in the AWS cloud.
•	Max 5 VPC can be created in one account and 200 subnets in one VPC.
•	We can allocate max 5 Elastic IP.
•	Once we created VPC- DHCP, NACL and security group will be automatically created.
•	A VPC is confined to an AWS region and does not extend between regions.

VPC will create in a Region

•	Subnet will create in AZ and in two AZ subnet will not same
•	Two VPC may have same CIDR because they are isolate from each other.
•	Once the VPC is created, you cannot change its CIDR block Range.
•	If you need a different CIDR size, create a new VPC.
•	The different subnets within  VPC cannot overlap.
•	You can however expond your VPC CIDR by adding new/Extra IP address Ranges (Except Gov-cloud and AWS-China)

Components of VPC: -

•	CIDR and Ip Address, Subnets
	Implied Router and Routing table 
	Internet Gateway
	Security Group
•	Network ACL
•	Virtual Private gateway
•	Peering connection
•	Elastic IP


Lab: -

Step 1: - Create two EC2 with User data in two different Private Subnet. This will download through NAT from public network. Open port 8080 also for Network CIDR. If you are create in one subnet then create in different AZ.
 

Step2: - Create war of maven-web-application and copy to jump server and then scp to both EC2 in private subnet under tomcat webapps.

Step3: - Configure Target Group , Load Balancer and listener for different-different application

 
 
Load-balancer: -

Load balancer -> create load balancer -> Network load balancer type -> name -> Scheme - Internet facing -> choose VPC - Mapping AZ and subnet (Min two) -> Listener (protocol, port and default action to target group) -Create a target group in another session protocol tcp port 8080 -> Health check settings -> create and add the servers check mark on include as pending

Loadbalancer - add target group -> create load balancer

Check all parameters of Load balancer and Target group

Access the loadbalancer url. Please allow your ip in SG of EC2 instances.

What is IAM?
--------------------
•	IAM allows you to manage users and their level of access to the AWS Console.
•	IAM user limit is 5000 per AWS account and at a time you can add 10 Users.
•	1000 IAM roles are limited in one account
•	IAM User can be a member of 10 groups
•	Maximum 2 access key can provide to one User.
•	Permission is assigned to any IAM users by the JSON Policies.

•	Programmatically access (access key and secret access key) – service user to access any service
•	Interactive login access (user and password) – AWS mgmt. Console login access
 

Identity Access Management (IAM) offers the following features:-
-------------------------------------------------------------------------------------------
•	Centralized control of your AWS account
•	Shared Access to your AWS account 
•	Granular Permissions
•	Identity Federation (including Active Directory, Facebook, Linkedin etc.)
•	Multifactor Authentication
•	Provide temporary access for users/devices and services where necessary
•	Allows you to set up your own password rotation policy
•	Integrates with many different AWS services
•	Supports PCI DSS Compliance
•	 Your whole AWS security is there:
•	Users
•	Groups
•	Roles
•	Policies
•	Root account should never be used (and shared)
•	Users must be created with proper permissions
•	IAM is at the center of AWS
•	Policies are written in JSON (JavaScript Object Notation)
•	IAM has a global view
•	Permissions are governed by Policies (JSON)
•	MFA (Multi Factor Authentication) can be setup
•	IAM has predefined “managed policies”
•	It’s best to give users the minimal amount of
•	Big enterprises usually integrate their own repository of users with IAM
•	This way, one can login into AWS using their company credentials
•	Identity Federation uses the SAML standard (Active Directory)

Users: - End Users such as people, employees of an organization etc.

Groups: - A collection of users. Each user in the group will inherit the permission of the group.

Policies: - Policies are made up of documents. These documents are in a format called JSON and they give permission as to what a User/Group Role is able to do.

Roles: - You create roles and then assign them to AWS Resources.
Roles is the way by which you can use one AWS service to another AWS service. Example that if you want to give access to any EC2 instance to any S3 bucket.

 
Roles:-

Roles is the way by which you can use one AWS service to another AWS service. Example that if you want to give access to any EC2 instance to any S3 bucket.

Tips:-
----------
•	IAM is universal. It does not apply to regions at this time.
•	The "root account" is simply the account created when first setup your AWS account. It has complete Admin access.
•	New Users have NO permissions when first created.
•	New Users are assigned Access Key ID & Secret Access Keys when first created.
•	These are not the same as a password. You cannot use the Access key ID & Secret Access Key to Login in to the console. You can use this to access AWS via the APIs and command line, however.
•	You only get to view these once. If you lose them, you have to regenerate them. So, save them in a secure location. 
•	Always setup Multifactor Authentication on your root account.
•	You can create and customize your own password rotation policies.
•	One IAM User per PHYSICAL PERSON
•	One IAM Role per Application
•	IAM credentials should NEVER BE SHARED
•	Never, ever, ever, ever, write IAM credentials in code. EVER.
•	And even less, NEVER EVER EVER COMMIT YOUR IAM credentials
•	Never use the ROOT account except for initial setup.
•	Never use ROOT IAM Credentials



Day1: -

Traditinal Deployment
Virtualized Deployment
Conatiner Deployment

Difference between container and virtualization

Cgroup
Namespaces

Day2: -

Containerization Tools
-----------------------
Docker - It has very good CLI, API, GUI(community and Enetrprise Edition)
Container-D
Podman
CoreOS
CIR-O
Rocket

Container Orchestration Tools
-----------------------------
Docker Swarm
K8s
Openshift
Mesios

Docker EE
---------
DTR - > Docker Trusted Registry(Repository)
UCP -> Universal Control Pane (GUI for Docker and Docker swarm)

Why Containers?
---------------
QUickly create, ready to run
Automate testing, integration and packaging
Support microservices
Less time to start and light weight

Mirantis Aacquired Docker

Docker Desktop
----------------
1. WSL2 backend
2. Hyperv Enabled

Win10+ 64 bit and 4GB ram

Benifits of Docker
1. Portable
2. Cost saving
3. Scalable
4. Quick stop and Start
5. Quick deploy
6. Light weight
7. Easy to monitor
8. Secure

Docker Architecture
---------------------
1. Docker client - Docker cli - To send commands/instructions to docker
2. Docker daemon/engine/server/host/service - take input from User and execute that instructions/commands.
3. Docker Registry- place to maintain docker images
   1. Public registory - Docker Hub( central repository for most the softwraes as docker images)- http://hub.docker.com
   2. Private registory: - Docker registry, Nexus, jfrog, ECR(managed Registry- AWS), DTR, ACR(Azure), GCR(Google cloud) etc.
Run Docker container

Container: - Container is run time process of your image where your application will be running

Docker Image: - Image is a package (App code+, soft+lib, + configuration)

DockerFile: - Dockerfile is a file having instructions or steps to create an Image.

Lab1: - Create an Linux Instance(Amazon Linux, Centos, Ubuntu/Debian) and install Dokcer Engine

Community Edition officially it wont support Redhat.
Redhat officially doces not support Docker CE officially.